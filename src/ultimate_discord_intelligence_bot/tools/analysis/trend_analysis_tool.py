"""
Real-time trend analysis tool for content and social media trends.

This tool provides comprehensive trend analysis including:
- Real-time trend detection across platforms
- Cross-platform trend correlation
- Trend prediction and forecasting
- Viral content identification
- Audience behavior analysis
- Content performance prediction
"""

from __future__ import annotations

import logging
import time
from collections import Counter, defaultdict
from typing import Any, TypedDict

from ultimate_discord_intelligence_bot.obs.metrics import get_metrics
from ultimate_discord_intelligence_bot.step_result import StepResult

from ._base import BaseTool


class TrendDataPoint(TypedDict, total=False):
    """Individual trend data point."""

    timestamp: float
    platform: str
    content_id: str
    engagement_metrics: dict[str, Any]
    content_metadata: dict[str, Any]
    audience_data: dict[str, Any]


class TrendPattern(TypedDict, total=False):
    """Identified trend pattern."""

    pattern_id: str
    pattern_type: str
    confidence: float
    description: str
    keywords: list[str]
    platforms: list[str]
    time_range: dict[str, float]
    growth_rate: float
    peak_engagement: float


class ViralPrediction(TypedDict, total=False):
    """Viral content prediction."""

    content_id: str
    viral_probability: float
    predicted_reach: int
    predicted_engagement: float
    time_to_peak: float
    peak_duration: float
    factors: list[str]
    confidence: float


class CrossPlatformTrend(TypedDict, total=False):
    """Cross-platform trend analysis."""

    trend_id: str
    platforms: list[str]
    correlation_score: float
    lead_platform: str
    lag_platforms: list[str]
    trend_strength: float
    content_types: list[str]
    audience_overlap: float


class TrendForecast(TypedDict, total=False):
    """Trend forecasting result."""

    trend_id: str
    current_stage: str
    predicted_duration: float
    peak_prediction: dict[str, Any]
    decline_prediction: dict[str, Any]
    next_trends: list[str]
    confidence: float


class TrendAnalysisResult(TypedDict, total=False):
    """Complete trend analysis result."""

    current_trends: list[TrendPattern]
    viral_predictions: list[ViralPrediction]
    cross_platform_trends: list[CrossPlatformTrend]
    trend_forecasts: list[TrendForecast]
    audience_insights: dict[str, Any]
    content_recommendations: list[dict[str, Any]]
    trend_alerts: list[dict[str, Any]]
    processing_time: float
    metadata: dict[str, Any]


class TrendAnalysisTool(BaseTool[StepResult]):
    """Advanced real-time trend analysis with predictive capabilities."""

    name: str = "Trend Analysis Tool"
    description: str = (
        "Analyzes real-time trends across platforms, predicts viral content, and provides trend forecasting."
    )

    def __init__(
        self,
        enable_viral_prediction: bool = True,
        enable_cross_platform_analysis: bool = True,
        enable_forecasting: bool = True,
        trend_window_hours: int = 24,
        min_engagement_threshold: int = 100,
        viral_threshold: float = 0.7,
        correlation_threshold: float = 0.6,
    ):
        super().__init__()
        self._enable_viral_prediction = enable_viral_prediction
        self._enable_cross_platform_analysis = enable_cross_platform_analysis
        self._enable_forecasting = enable_forecasting
        self._trend_window_hours = trend_window_hours
        self._min_engagement_threshold = min_engagement_threshold
        self._viral_threshold = viral_threshold
        self._correlation_threshold = correlation_threshold
        self._metrics = get_metrics()

        # In-memory trend storage
        self._trend_data: list[TrendDataPoint] = []
        self._trend_patterns: list[TrendPattern] = []
        self._viral_predictions: list[ViralPrediction] = []

    def _run(
        self,
        content_data: list[TrendDataPoint] | None = None,
        platform_data: dict[str, Any] | None = None,
        analysis_config: dict[str, Any] | None = None,
        tenant: str = "default",
        workspace: str = "default",
        analysis_depth: str = "comprehensive",
    ) -> StepResult:
        """
        Perform comprehensive trend analysis.

        Args:
            content_data: Recent content data points for analysis
            platform_data: Platform-specific data and metrics
            analysis_config: Configuration for trend analysis
            tenant: Tenant identifier for isolation
            workspace: Workspace identifier
            analysis_depth: Depth of analysis (basic, comprehensive, detailed)

        Returns:
            StepResult with comprehensive trend analysis
        """
        start_time = time.monotonic()

        try:
            # Input validation
            if not content_data:
                content_data = []

            if tenant and workspace:
                self.note(f"Starting trend analysis for {len(content_data)} data points")

            # Update trend data
            self._update_trend_data(content_data)

            # Perform trend analysis
            current_trends = self._identify_current_trends()
            viral_predictions = self._predict_viral_content() if self._enable_viral_prediction else []
            cross_platform_trends = (
                self._analyze_cross_platform_trends() if self._enable_cross_platform_analysis else []
            )
            trend_forecasts = self._forecast_trends() if self._enable_forecasting else []
            audience_insights = self._analyze_audience_behavior()
            content_recommendations = self._generate_content_recommendations(current_trends, viral_predictions)
            trend_alerts = self._generate_trend_alerts(current_trends, viral_predictions)

            processing_time = time.monotonic() - start_time

            result: TrendAnalysisResult = {
                "current_trends": current_trends,
                "viral_predictions": viral_predictions,
                "cross_platform_trends": cross_platform_trends,
                "trend_forecasts": trend_forecasts,
                "audience_insights": audience_insights,
                "content_recommendations": content_recommendations,
                "trend_alerts": trend_alerts,
                "processing_time": processing_time,
                "metadata": {
                    "analysis_depth": analysis_depth,
                    "data_points_analyzed": len(self._trend_data),
                    "trend_window_hours": self._trend_window_hours,
                    "tenant": tenant,
                    "workspace": workspace,
                    "timestamp": time.time(),
                },
            }

            self._metrics.counter("tool_runs_total", labels={"tool": self.name, "outcome": "success"}).inc()
            self._metrics.histogram("tool_run_seconds", processing_time, labels={"tool": self.name})

            return StepResult.ok(data=result)

        except Exception as e:
            processing_time = time.monotonic() - start_time
            self._metrics.counter("tool_runs_total", labels={"tool": self.name, "outcome": "error"}).inc()
            logging.exception("Trend analysis failed")
            return StepResult.fail(f"Trend analysis failed: {e!s}")

    def _update_trend_data(self, new_data: list[TrendDataPoint]) -> None:
        """Update trend data with new content data points."""
        current_time = time.time()
        cutoff_time = current_time - (self._trend_window_hours * 3600)

        # Add new data
        self._trend_data.extend(new_data)

        # Remove old data outside the time window
        self._trend_data = [data for data in self._trend_data if data.get("timestamp", 0) > cutoff_time]

        # Sort by timestamp
        self._trend_data.sort(key=lambda x: x.get("timestamp", 0))

    def _identify_current_trends(self) -> list[TrendPattern]:
        """Identify current trending patterns."""
        if not self._trend_data:
            return []

        trends: list[TrendPattern] = []
        current_time = time.time()

        # Analyze keyword trends
        keyword_trends = self._analyze_keyword_trends()
        for keyword, trend_data in keyword_trends.items():
            if trend_data["growth_rate"] > 0.5:  # 50% growth threshold
                keyword_trend: TrendPattern = {
                    "pattern_id": f"keyword_{keyword}",
                    "pattern_type": "keyword_trend",
                    "confidence": min(1.0, trend_data["growth_rate"]),
                    "description": f"Rising trend in '{keyword}' content",
                    "keywords": [keyword],
                    "platforms": trend_data["platforms"],
                    "time_range": {
                        "start": current_time - (self._trend_window_hours * 3600),
                        "end": current_time,
                    },
                    "growth_rate": trend_data["growth_rate"],
                    "peak_engagement": trend_data["peak_engagement"],
                }
                trends.append(keyword_trend)

        # Analyze content type trends
        content_type_trends = self._analyze_content_type_trends()
        for content_type, trend_data in content_type_trends.items():
            if trend_data["growth_rate"] > 0.3:  # 30% growth threshold
                content_trend: TrendPattern = {
                    "pattern_id": f"content_type_{content_type}",
                    "pattern_type": "content_type_trend",
                    "confidence": min(1.0, trend_data["growth_rate"]),
                    "description": f"Rising trend in {content_type} content",
                    "keywords": [],
                    "platforms": trend_data["platforms"],
                    "time_range": {
                        "start": current_time - (self._trend_window_hours * 3600),
                        "end": current_time,
                    },
                    "growth_rate": trend_data["growth_rate"],
                    "peak_engagement": trend_data["peak_engagement"],
                }
                trends.append(content_trend)

        # Analyze engagement pattern trends
        engagement_trends = self._analyze_engagement_patterns()
        for pattern, trend_data in engagement_trends.items():
            if trend_data["growth_rate"] > 0.4:  # 40% growth threshold
                trend: TrendPattern = {
                    "pattern_id": f"engagement_{pattern}",
                    "pattern_type": "engagement_trend",
                    "confidence": min(1.0, trend_data["growth_rate"]),
                    "description": f"Rising {pattern} engagement pattern",
                    "keywords": [],
                    "platforms": trend_data["platforms"],
                    "time_range": {
                        "start": current_time - (self._trend_window_hours * 3600),
                        "end": current_time,
                    },
                    "growth_rate": trend_data["growth_rate"],
                    "peak_engagement": trend_data["peak_engagement"],
                }
                trends.append(trend)

        return trends

    def _predict_viral_content(self) -> list[ViralPrediction]:
        """Predict which content has viral potential."""
        if not self._trend_data:
            return []

        predictions = []
        current_time = time.time()

        # Analyze recent content for viral potential
        recent_content = [
            data
            for data in self._trend_data
            if current_time - data.get("timestamp", 0) <= 3600  # Last hour
        ]

        for content in recent_content:
            viral_probability = self._calculate_viral_probability(content)
            if viral_probability > self._viral_threshold:
                prediction: ViralPrediction = {
                    "content_id": content.get("content_id", ""),
                    "viral_probability": viral_probability,
                    "predicted_reach": self._predict_reach(content, viral_probability),
                    "predicted_engagement": self._predict_engagement(content, viral_probability),
                    "time_to_peak": self._predict_time_to_peak(content),
                    "peak_duration": self._predict_peak_duration(content),
                    "factors": self._identify_viral_factors(content),
                    "confidence": viral_probability,
                }
                predictions.append(prediction)

        return predictions

    def _analyze_cross_platform_trends(self) -> list[CrossPlatformTrend]:
        """Analyze trends across multiple platforms."""
        if not self._trend_data:
            return []

        cross_platform_trends: list[CrossPlatformTrend] = []
        platforms = list({data.get("platform", "") for data in self._trend_data})

        if len(platforms) < 2:
            return cross_platform_trends

        # Analyze keyword correlation across platforms
        keyword_correlations = self._analyze_keyword_correlations(platforms)
        for keyword, correlation_data in keyword_correlations.items():
            if correlation_data["correlation_score"] > self._correlation_threshold:
                trend: CrossPlatformTrend = {
                    "trend_id": f"cross_platform_{keyword}",
                    "platforms": correlation_data["platforms"],
                    "correlation_score": correlation_data["correlation_score"],
                    "lead_platform": correlation_data["lead_platform"],
                    "lag_platforms": correlation_data["lag_platforms"],
                    "trend_strength": correlation_data["trend_strength"],
                    "content_types": correlation_data["content_types"],
                    "audience_overlap": correlation_data["audience_overlap"],
                }
                cross_platform_trends.append(trend)

        return cross_platform_trends

    def _forecast_trends(self) -> list[TrendForecast]:
        """Forecast future trend development."""
        if not self._trend_data:
            return []

        forecasts = []
        current_trends = self._identify_current_trends()

        for trend in current_trends:
            forecast: TrendForecast = {
                "trend_id": trend["pattern_id"],
                "current_stage": self._determine_trend_stage(trend),
                "predicted_duration": self._predict_trend_duration(trend),
                "peak_prediction": self._predict_trend_peak(trend),
                "decline_prediction": self._predict_trend_decline(trend),
                "next_trends": self._predict_next_trends(trend),
                "confidence": trend["confidence"] * 0.8,  # Reduce confidence for forecasting
            }
            forecasts.append(forecast)

        return forecasts

    def _analyze_audience_behavior(self) -> dict[str, Any]:
        """Analyze audience behavior patterns."""
        if not self._trend_data:
            return {"behavior_patterns": [], "engagement_preferences": {}}

        # Analyze engagement patterns by time
        time_patterns = self._analyze_time_patterns()

        # Analyze content preferences
        content_preferences = self._analyze_content_preferences()

        # Analyze platform preferences
        platform_preferences = self._analyze_platform_preferences()

        return {
            "behavior_patterns": time_patterns,
            "engagement_preferences": content_preferences,
            "platform_preferences": platform_preferences,
            "audience_segments": self._identify_audience_segments(),
        }

    def _generate_content_recommendations(
        self,
        current_trends: list[TrendPattern],
        viral_predictions: list[ViralPrediction],
    ) -> list[dict[str, Any]]:
        """Generate content recommendations based on trends."""
        recommendations = []

        # Recommendations based on current trends
        for trend in current_trends:
            if trend["confidence"] > 0.7:
                recommendation = {
                    "type": "trend_based",
                    "priority": "high" if trend["confidence"] > 0.8 else "medium",
                    "description": f"Create content around trending topic: {', '.join(trend['keywords'])}",
                    "platforms": trend["platforms"],
                    "expected_engagement": trend["peak_engagement"],
                    "confidence": trend["confidence"],
                }
                recommendations.append(recommendation)

        # Recommendations based on viral predictions
        for prediction in viral_predictions:
            if prediction["viral_probability"] > 0.8:
                recommendation = {
                    "type": "viral_opportunity",
                    "priority": "high",
                    "description": f"High viral potential content identified: {prediction['content_id']}",
                    "expected_reach": prediction["predicted_reach"],
                    "expected_engagement": prediction["predicted_engagement"],
                    "confidence": prediction["confidence"],
                }
                recommendations.append(recommendation)

        return recommendations

    def _generate_trend_alerts(
        self,
        current_trends: list[TrendPattern],
        viral_predictions: list[ViralPrediction],
    ) -> list[dict[str, Any]]:
        """Generate trend alerts for significant developments."""
        alerts = []

        # High-confidence trend alerts
        for trend in current_trends:
            if trend["confidence"] > 0.9:
                alert = {
                    "type": "trend_alert",
                    "severity": "high",
                    "message": f"High-confidence trend detected: {trend['description']}",
                    "trend_id": trend["pattern_id"],
                    "confidence": trend["confidence"],
                    "action_required": "immediate_content_creation",
                }
                alerts.append(alert)

        # Viral prediction alerts
        for prediction in viral_predictions:
            if prediction["viral_probability"] > 0.9:
                alert = {
                    "type": "viral_alert",
                    "severity": "high",
                    "message": f"High viral potential detected: {prediction['content_id']}",
                    "content_id": prediction["content_id"],
                    "viral_probability": prediction["viral_probability"],
                    "action_required": "amplify_content",
                }
                alerts.append(alert)

        return alerts

    def _analyze_keyword_trends(self) -> dict[str, dict[str, Any]]:
        """Analyze keyword trends over time."""
        keyword_data: dict[str, dict[str, Any]] = defaultdict(
            lambda: {"counts": [], "platforms": set(), "engagements": []}
        )
        current_time = time.time()

        # Group data by time windows
        time_windows = 6  # 6 windows for 24-hour analysis
        window_size = (self._trend_window_hours * 3600) / time_windows

        for data in self._trend_data:
            content_metadata = data.get("content_metadata", {})
            keywords = content_metadata.get("keywords", [])
            platform = data.get("platform", "")
            engagement = data.get("engagement_metrics", {}).get("total_engagement", 0)

            # Determine time window
            timestamp = data.get("timestamp", 0)
            window_index = int((current_time - timestamp) / window_size)

            for keyword in keywords:
                keyword_data[keyword]["platforms"].add(platform)
                keyword_data[keyword]["engagements"].append(engagement)

                # Ensure we have enough data points
                while len(keyword_data[keyword]["counts"]) <= window_index:
                    keyword_data[keyword]["counts"].append(0)

                keyword_data[keyword]["counts"][window_index] += 1

        # Calculate growth rates
        keyword_trends = {}
        for keyword, data in keyword_data.items():
            counts = data["counts"]
            if len(counts) >= 2:
                recent_count = sum(counts[:2])  # Recent 2 windows
                older_count = sum(counts[2:])  # Older windows

                if older_count > 0:
                    growth_rate = (recent_count - older_count) / older_count
                    peak_engagement = max(data["engagements"]) if data["engagements"] else 0

                    keyword_trends[keyword] = {
                        "growth_rate": growth_rate,
                        "platforms": list(data["platforms"]),
                        "peak_engagement": peak_engagement,
                    }

        return keyword_trends

    def _analyze_content_type_trends(self) -> dict[str, dict[str, Any]]:
        """Analyze content type trends over time."""
        content_type_data: dict[str, dict[str, Any]] = defaultdict(
            lambda: {"counts": [], "platforms": set(), "engagements": []}
        )
        current_time = time.time()

        # Group data by time windows
        time_windows = 6
        window_size = (self._trend_window_hours * 3600) / time_windows

        for data in self._trend_data:
            content_metadata = data.get("content_metadata", {})
            content_type = content_metadata.get("content_type", "unknown")
            platform = data.get("platform", "")
            engagement = data.get("engagement_metrics", {}).get("total_engagement", 0)

            # Determine time window
            timestamp = data.get("timestamp", 0)
            window_index = int((current_time - timestamp) / window_size)

            content_type_data[content_type]["platforms"].add(platform)
            content_type_data[content_type]["engagements"].append(engagement)

            # Ensure we have enough data points
            while len(content_type_data[content_type]["counts"]) <= window_index:
                content_type_data[content_type]["counts"].append(0)

            content_type_data[content_type]["counts"][window_index] += 1

        # Calculate growth rates
        content_type_trends = {}
        for content_type, data in content_type_data.items():
            counts = data["counts"]
            if len(counts) >= 2:
                recent_count = sum(counts[:2])
                older_count = sum(counts[2:])

                if older_count > 0:
                    growth_rate = (recent_count - older_count) / older_count
                    peak_engagement = max(data["engagements"]) if data["engagements"] else 0

                    content_type_trends[content_type] = {
                        "growth_rate": growth_rate,
                        "platforms": list(data["platforms"]),
                        "peak_engagement": peak_engagement,
                    }

        return content_type_trends

    def _analyze_engagement_patterns(self) -> dict[str, dict[str, Any]]:
        """Analyze engagement pattern trends."""
        # This is a simplified implementation
        # In a real system, this would analyze complex engagement patterns

        patterns = {}
        time.time()

        # Analyze high engagement content
        high_engagement_content = [
            data
            for data in self._trend_data
            if data.get("engagement_metrics", {}).get("total_engagement", 0) > self._min_engagement_threshold
        ]

        if len(high_engagement_content) > 10:
            patterns["high_engagement"] = {
                "growth_rate": 0.6,  # Simplified calculation
                "platforms": list({data.get("platform", "") for data in high_engagement_content}),
                "peak_engagement": max(
                    data.get("engagement_metrics", {}).get("total_engagement", 0) for data in high_engagement_content
                ),
            }

        return patterns

    def _calculate_viral_probability(self, content: TrendDataPoint) -> float:
        """Calculate viral probability for content."""
        engagement_metrics = content.get("engagement_metrics", {})
        content_metadata = content.get("content_metadata", {})

        # Base probability from engagement rate
        total_engagement = engagement_metrics.get("total_engagement", 0)
        views = engagement_metrics.get("views", 1)
        engagement_rate = total_engagement / max(1, views)

        # Adjust for content type
        content_type = content_metadata.get("content_type", "unknown")
        type_multiplier = {
            "video": 1.2,
            "image": 1.0,
            "text": 0.8,
            "audio": 0.9,
        }.get(content_type, 1.0)

        # Adjust for recency
        current_time = time.time()
        timestamp = content.get("timestamp", 0)
        recency_factor = max(0.5, 1.0 - (current_time - timestamp) / 3600)  # Decay over hour

        viral_probability = min(1.0, engagement_rate * type_multiplier * recency_factor)
        return viral_probability

    def _predict_reach(self, content: TrendDataPoint, viral_probability: float) -> int:
        """Predict potential reach for content."""
        current_views = content.get("engagement_metrics", {}).get("views", 0)
        predicted_multiplier = 1 + (viral_probability * 10)  # Up to 10x reach
        return int(current_views * predicted_multiplier)

    def _predict_engagement(self, content: TrendDataPoint, viral_probability: float) -> float:
        """Predict potential engagement for content."""
        current_engagement = content.get("engagement_metrics", {}).get("total_engagement", 0)
        predicted_multiplier = 1 + (viral_probability * 5)  # Up to 5x engagement
        return current_engagement * predicted_multiplier

    def _predict_time_to_peak(self, content: TrendDataPoint) -> float:
        """Predict time to reach peak engagement."""
        # Simplified prediction based on content type and current performance
        content_type = content.get("content_metadata", {}).get("content_type", "unknown")
        base_time = {
            "video": 2.0,  # 2 hours
            "image": 1.0,  # 1 hour
            "text": 0.5,  # 30 minutes
            "audio": 1.5,  # 1.5 hours
        }.get(content_type, 1.0)

        # Adjust based on current engagement
        current_engagement = content.get("engagement_metrics", {}).get("total_engagement", 0)
        if current_engagement > 1000:
            base_time *= 0.5  # Faster if already performing well

        return base_time

    def _predict_peak_duration(self, content: TrendDataPoint) -> float:
        """Predict duration of peak engagement."""
        content_type = content.get("content_metadata", {}).get("content_type", "unknown")
        return {
            "video": 6.0,  # 6 hours
            "image": 3.0,  # 3 hours
            "text": 2.0,  # 2 hours
            "audio": 4.0,  # 4 hours
        }.get(content_type, 3.0)

    def _identify_viral_factors(self, content: TrendDataPoint) -> list[str]:
        """Identify factors contributing to viral potential."""
        factors = []

        engagement_metrics = content.get("engagement_metrics", {})
        content_metadata = content.get("content_metadata", {})

        # High engagement rate
        total_engagement = engagement_metrics.get("total_engagement", 0)
        views = engagement_metrics.get("views", 1)
        if total_engagement / views > 0.1:
            factors.append("high_engagement_rate")

        # Trending keywords
        keywords = content_metadata.get("keywords", [])
        if len(keywords) > 3:
            factors.append("trending_keywords")

        # Multiple platforms
        platform = content.get("platform", "")
        if platform in ["youtube", "tiktok", "instagram"]:
            factors.append("viral_platform")

        # Recent content
        current_time = time.time()
        timestamp = content.get("timestamp", 0)
        if current_time - timestamp < 3600:  # Less than 1 hour old
            factors.append("recent_content")

        return factors

    def _analyze_keyword_correlations(self, platforms: list[str]) -> dict[str, dict[str, Any]]:
        """Analyze keyword correlations across platforms."""
        correlations = {}

        # Get keywords for each platform
        platform_keywords = {}
        for platform in platforms:
            platform_data = [data for data in self._trend_data if data.get("platform") == platform]
            keywords = []
            for data in platform_data:
                content_metadata = data.get("content_metadata", {})
                keywords.extend(content_metadata.get("keywords", []))
            platform_keywords[platform] = Counter(keywords)

        # Find common keywords
        all_keywords = set()
        for keywords in platform_keywords.values():
            all_keywords.update(keywords.keys())

        for keyword in all_keywords:
            platform_counts = {}
            for platform, keywords in platform_keywords.items():
                platform_counts[platform] = keywords.get(keyword, 0)

            # Calculate correlation
            if len([count for count in platform_counts.values() if count > 0]) >= 2:
                correlation_score = self._calculate_correlation_score(platform_counts)
                if correlation_score > self._correlation_threshold:
                    correlations[keyword] = {
                        "correlation_score": correlation_score,
                        "platforms": [platform for platform, count in platform_counts.items() if count > 0],
                        "lead_platform": max(platform_counts.items(), key=lambda x: x[1])[0],
                        "lag_platforms": [
                            platform
                            for platform, count in platform_counts.items()
                            if count < max(platform_counts.values())
                        ],
                        "trend_strength": sum(platform_counts.values()),
                        "content_types": [],  # Simplified
                        "audience_overlap": 0.5,  # Simplified
                    }

        return correlations

    def _calculate_correlation_score(self, platform_counts: dict[str, int]) -> float:
        """Calculate correlation score between platforms."""
        counts = list(platform_counts.values())
        if len(counts) < 2:
            return 0.0

        # Simple correlation based on count similarity
        max_count = max(counts)
        min_count = min(counts)

        if max_count == 0:
            return 0.0

        # Higher correlation if counts are more similar
        similarity = 1.0 - (max_count - min_count) / max_count
        return similarity

    def _determine_trend_stage(self, trend: TrendPattern) -> str:
        """Determine current stage of trend."""
        growth_rate = trend.get("growth_rate", 0.0)

        if growth_rate > 1.0:
            return "explosive_growth"
        elif growth_rate > 0.5:
            return "rapid_growth"
        elif growth_rate > 0.2:
            return "steady_growth"
        elif growth_rate > 0.0:
            return "early_stage"
        else:
            return "declining"

    def _predict_trend_duration(self, trend: TrendPattern) -> float:
        """Predict how long the trend will last."""
        growth_rate = trend.get("growth_rate", 0.0)
        confidence = trend.get("confidence", 0.0)

        # Base duration based on growth rate
        if growth_rate > 1.0:
            base_duration = 2.0  # 2 days
        elif growth_rate > 0.5:
            base_duration = 5.0  # 5 days
        elif growth_rate > 0.2:
            base_duration = 10.0  # 10 days
        else:
            base_duration = 3.0  # 3 days

        # Adjust by confidence
        return base_duration * confidence

    def _predict_trend_peak(self, trend: TrendPattern) -> dict[str, Any]:
        """Predict when and how high the trend will peak."""
        current_engagement = trend.get("peak_engagement", 0)
        growth_rate = trend.get("growth_rate", 0.0)

        peak_engagement = current_engagement * (1 + growth_rate)
        time_to_peak = 1.0  # Simplified: 1 day to peak

        return {
            "peak_engagement": peak_engagement,
            "time_to_peak": time_to_peak,
            "confidence": trend.get("confidence", 0.0),
        }

    def _predict_trend_decline(self, trend: TrendPattern) -> dict[str, Any]:
        """Predict trend decline characteristics."""
        return {
            "decline_rate": 0.1,  # 10% per day
            "time_to_decline": 3.0,  # 3 days
            "final_engagement": trend.get("peak_engagement", 0) * 0.1,
        }

    def _predict_next_trends(self, trend: TrendPattern) -> list[str]:
        """Predict what trends might follow this one."""
        # Simplified prediction based on trend type
        trend_type = trend.get("pattern_type", "")

        if trend_type == "keyword_trend":
            return ["related_keywords", "content_adaptation", "cross_platform_spread"]
        elif trend_type == "content_type_trend":
            return ["format_evolution", "audience_expansion", "platform_adaptation"]
        else:
            return ["general_evolution", "audience_shift"]

    def _analyze_time_patterns(self) -> list[dict[str, Any]]:
        """Analyze audience behavior patterns by time."""
        # Simplified time pattern analysis
        return [
            {
                "pattern": "peak_hours",
                "hours": [18, 19, 20, 21],  # 6-9 PM
                "engagement_multiplier": 1.5,
            },
            {
                "pattern": "low_activity",
                "hours": [2, 3, 4, 5],  # 2-5 AM
                "engagement_multiplier": 0.3,
            },
        ]

    def _analyze_content_preferences(self) -> dict[str, Any]:
        """Analyze audience content preferences."""
        if not self._trend_data:
            return {}

        content_types = Counter()
        for data in self._trend_data:
            content_metadata = data.get("content_metadata", {})
            content_type = content_metadata.get("content_type", "unknown")
            content_types[content_type] += 1

        return dict(content_types.most_common())

    def _analyze_platform_preferences(self) -> dict[str, Any]:
        """Analyze audience platform preferences."""
        if not self._trend_data:
            return {}

        platforms = Counter()
        for data in self._trend_data:
            platform = data.get("platform", "unknown")
            platforms[platform] += 1

        return dict(platforms.most_common())

    def _identify_audience_segments(self) -> list[dict[str, Any]]:
        """Identify different audience segments."""
        # Simplified audience segmentation
        return [
            {
                "segment": "high_engagement",
                "characteristics": ["frequent_interaction", "early_adopter"],
                "size": 0.2,
            },
            {
                "segment": "casual_viewer",
                "characteristics": ["occasional_interaction", "content_consumer"],
                "size": 0.6,
            },
            {
                "segment": "lurker",
                "characteristics": ["minimal_interaction", "passive_consumer"],
                "size": 0.2,
            },
        ]

    def run(
        self,
        content_data: list[TrendDataPoint] | None = None,
        platform_data: dict[str, Any] | None = None,
        analysis_config: dict[str, Any] | None = None,
        tenant: str = "default",
        workspace: str = "default",
        analysis_depth: str = "comprehensive",
    ) -> StepResult:
        """Public interface for trend analysis."""
        return self._run(
            content_data,
            platform_data,
            analysis_config,
            tenant,
            workspace,
            analysis_depth,
        )
