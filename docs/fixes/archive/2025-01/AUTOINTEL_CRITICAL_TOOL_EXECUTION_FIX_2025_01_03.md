# üö® CRITICAL FIX: CrewAI Agents Not Executing Tools (2025-01-03)

## Problem Diagnosis

### Evidence from Logs

```
Agent: Transcription & Index Engineer
Final Answer:
{
  "transcript": "Your transcribed text goes here...",  # ‚ùå PLACEHOLDER (34 chars)
  "timeline_anchors": [...],  # ‚ùå MOCK DATA
}
```

```
Agent: Analysis Cartographer
Final Answer:
{
  "insights": <extracted_insights>,  # ‚ùå INVALID JSON
  "themes": <identified_themes>,
}
‚ùå Failed to parse JSON from task output
```

```
Agent: Verification Director
Final Answer:
{
  "verified_claims": [],  # ‚ùå EMPTY - ClaimExtractorTool never called
  "fact_check_results": [],
  "trustworthiness_score": 0
}
(Note: Since I cannot extract or validate real data without the actual transcript...)
```

```
Agent: Knowledge Integration Steward
Final Answer:
{
  "memory_stored": true,  # ‚ùå CLAIMED but MemoryStorageTool never called
  "graph_created": true,  # ‚ùå CLAIMED but GraphMemoryTool never called
}
```

### Root Cause

CrewAI agents are **generating placeholder JSON responses** instead of **executing actual tools**. This happens because:

1. **LLM Default Behavior**: Language models prefer to generate responses rather than call tools
2. **Task Instructions Too Permissive**: "Use AudioTranscriptionTool" is a suggestion, not a requirement
3. **No Tool Enforcement**: CrewAI doesn't have `force_tool` or `require_tool` parameters
4. **Missing Tool Call Verification**: No validation that tools were actually invoked

## Solution: Multi-Layered Tool Enforcement

### Fix #10: Add Explicit Tool-Forcing Task Instructions

**Change task descriptions from permissive to imperative:**

**BEFORE (Permissive):**

```python
"STEP 2: Use AudioTranscriptionTool with the file_path parameter to transcribe the media."
```

**AFTER (Imperative):**

```python
"STEP 2: YOU MUST CALL AudioTranscriptionTool(file_path=<extracted_path>). 
DO NOT generate mock transcript data. 
DO NOT respond until the tool returns actual results.
VALIDATION: Tool output must contain 'transcript' field with 1000+ characters."
```

### Fix #11: Add Tool Call Verification in Callbacks

**Modify `_task_completion_callback` to detect placeholder responses:**

```python
def _task_completion_callback(self, task_output: Any) -> None:
    # ... existing code ...
    
    # NEW: Detect placeholder/mock responses
    if "transcript" in output_data:
        transcript = output_data["transcript"]
        if transcript and len(transcript) < 100:
            self.logger.error(
                f"‚ùå TOOL EXECUTION FAILURE: transcript too short ({len(transcript)} chars). "
                f"Agent likely generated placeholder instead of calling AudioTranscriptionTool!"
            )
        if "goes here" in transcript.lower() or "your transcribed" in transcript.lower():
            self.logger.error(
                f"‚ùå TOOL EXECUTION FAILURE: Detected placeholder text in transcript. "
                f"Agent MUST call AudioTranscriptionTool, not generate mock data!"
            )
    
    if "verified_claims" in output_data:
        claims = output_data["verified_claims"]
        if isinstance(claims, list) and len(claims) == 0:
            self.logger.warning(
                f"‚ö†Ô∏è  SUSPICIOUS: verified_claims is empty. "
                f"Verify ClaimExtractorTool was actually called."
            )
```

### Fix #12: Add Agent-Level Tool Instructions

**Modify agent backstories to emphasize tool usage:**

```python
def transcription_engineer(self) -> Agent:
    return Agent(
        role="Transcription & Index Engineer",
        goal="Deliver reliable transcripts using AudioTranscriptionTool",
        backstory=(
            "Audio/linguistic processing expert. "
            "CRITICAL: You MUST use tools to generate real data. "
            "NEVER generate placeholder text like 'Your transcribed text goes here'. "
            "NEVER return mock JSON. Tools exist for a reason - USE THEM!"
        ),
        tools=[...],
        verbose=True,
        allow_delegation=False,
    )
```

### Fix #13: Add Expected Output Validation

**Modify task descriptions to include validation criteria:**

```python
transcription_task = Task(
    description=(...),
    expected_output=(
        "JSON with transcript (min 1000 chars), timeline_anchors (list of dicts), "
        "transcript_length (int), quality_score (0.0-1.0). "
        "\n\n‚ùå REJECT: Placeholder text like 'Your transcribed text goes here'. "
        "\n‚ùå REJECT: transcript_length < 100. "
        "\n‚úÖ ACCEPT: Real transcript with actual spoken words from the media file."
    ),
    agent=transcription_agent,
    callback=self._task_completion_callback,
)
```

### Fix #14: Add Tool Call Logging

**Instrument `wrap_tool_for_crewai` to log every tool execution:**

```python
def wrap_tool_for_crewai(tool: BaseTool) -> Any:
    # ... existing code ...
    
    def instrumented_run(*args, **kwargs):
        # Log tool call BEFORE execution
        logger.warning(f"üîß TOOL CALLED: {tool_name} with args={args}, kwargs={kwargs}")
        
        result = original_run(*args, **kwargs)
        
        # Log tool result AFTER execution
        result_preview = str(result)[:200] if result else "None"
        logger.warning(f"‚úÖ TOOL RETURNED: {tool_name} ‚Üí {result_preview}")
        
        return result
    
    wrapper._run = instrumented_run
```

## Implementation Plan

1. **Update Task Descriptions** (autonomous_orchestrator.py)
   - Change all "Use X tool" ‚Üí "YOU MUST CALL X tool"
   - Add validation criteria to expected_output
   - Add rejection criteria for placeholder responses

2. **Add Tool Call Verification** (_task_completion_callback)
   - Detect placeholder text patterns
   - Validate data minimums (transcript > 100 chars)
   - Log warnings for suspicious empty results

3. **Update Agent Backstories** (crew.py)
   - Emphasize tool usage in backstory
   - Explicitly forbid placeholder generation
   - Add tool-first philosophy

4. **Add Tool Call Logging** (crewai_tool_wrappers.py)
   - Log every tool invocation
   - Log every tool result
   - Use WARNING level for visibility in logs

## Expected Behavior After Fixes

### Before (BROKEN)

```
Agent: Transcription & Index Engineer
Final Answer: {"transcript": "Your transcribed text goes here...", ...}
# NO tool calls logged
```

### After (WORKING)

```
Agent: Transcription & Index Engineer
üîß TOOL CALLED: AudioTranscriptionTool with kwargs={'file_path': '/tmp/video.mp4'}
‚úÖ TOOL RETURNED: AudioTranscriptionTool ‚Üí {"transcript": "Welcome to the show...", ...} (4523 chars)
Final Answer: {"transcript": "Welcome to the show. Today we're discussing...", ...}
```

## Testing Checklist

- [ ] Run `/autointel` with same Twitch video URL
- [ ] Check logs for "üîß TOOL CALLED: AudioTranscriptionTool"
- [ ] Verify transcript length > 1000 characters
- [ ] Check logs for "üîß TOOL CALLED: ClaimExtractorTool"
- [ ] Verify claims mention Twitch/Ethan Klein (not generic topics)
- [ ] Check logs for "üîß TOOL CALLED: MemoryStorageTool"
- [ ] Check logs for "üîß TOOL CALLED: GraphMemoryTool"
- [ ] Verify final briefing has specific video details

## Metrics to Monitor

- `autointel_tool_calls_total{tool="AudioTranscriptionTool"}` should be > 0
- `autointel_tool_calls_total{tool="ClaimExtractorTool"}` should be > 0
- `autointel_tool_calls_total{tool="MemoryStorageTool"}` should be > 0
- `autointel_tool_calls_total{tool="GraphMemoryTool"}` should be > 0

## Fallback: Force Tool Execution Pattern

If LLMs still refuse to call tools, implement manual tool execution in callbacks:

```python
def _task_completion_callback(self, task_output: Any) -> None:
    # ... existing code ...
    
    # FALLBACK: If agent didn't call tool, call it ourselves
    if task_name == "transcription" and "transcript" not in output_data:
        self.logger.error("‚ùå Agent failed to call AudioTranscriptionTool. Calling manually...")
        file_path = _GLOBAL_CREW_CONTEXT.get("file_path")
        if file_path:
            tool = AudioTranscriptionTool()
            result = tool.run(file_path=file_path)
            output_data.update(result.data if hasattr(result, 'data') else {})
```

## Status

- [x] Problem diagnosed (agents generating placeholders instead of calling tools)
- [ ] Fix #10 implemented (imperative task instructions)
- [ ] Fix #11 implemented (tool call verification in callbacks)
- [ ] Fix #12 implemented (agent backstory emphasis)
- [ ] Fix #13 implemented (expected output validation)
- [ ] Fix #14 implemented (tool call logging)
- [ ] E2E validation pending

## Related Files

- `src/ultimate_discord_intelligence_bot/autonomous_orchestrator.py` - Task descriptions, callbacks
- `src/ultimate_discord_intelligence_bot/crew.py` - Agent definitions
- `src/ultimate_discord_intelligence_bot/crewai_tool_wrappers.py` - Tool wrapper instrumentation
